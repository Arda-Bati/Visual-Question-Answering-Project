# SAMS_VQA

## Description 

This is project SAMS_VQA developed by the team composed of Arda Bati, Marjan Emadi, So Sasaki, and Sina Shahsavari.

The repository mainly consists of two implementations of Visual Question Answering (VQA). 

- The experiment1 is an implementation for Bottom-Up and Top-Down Attention for VQA, which our final report is based on. 
- The experiment2 is a different implementation of the vanilla VQA Model. The details are on the README file in each experiment directory.  

## Requirements and Usage

### Experiment1

Please refer to the experiment1 folder.

### Experiment2

Please refer to the experiment2 folder.

### Miscellaneous scripts

 - misc: Miscellaneous scripts
 - misc/data_format_check.ipynb: Script for preliminary data visualization 
 - misc/some_useful_codes: Scripts which were not used after all

## References

### Experiment1

 - https://arxiv.org/abs/1707.07998 
 - https://github.com/hengyuan-hu/bottom-up-attention-vqa. 
 - http://www.visualqa.org/challenge.html
 - http://www.visualqa.org/evaluation.html
 - https://arxiv.org/pdf/1611.09978.pdf

### Experiment2

 - https://github.com/Shivanshu-Gupta/Visual-Question-Answering
 - https://vqa.cloudcv.org/
 - https://arxiv.org/abs/1505.00468
 - https://arxiv.org/pdf/1511.02274
 - https://arxiv.org/abs/1705.06676
 - http://visualqa.org/download.html
 - https://github.com/Shivanshu-Gupta/Visual-Question-Answering/config
